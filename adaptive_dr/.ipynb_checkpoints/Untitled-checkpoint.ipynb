{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2806a8ae-0c8f-495a-b642-a644ce690882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francescocapuano/opt/anaconda3/envs/polienv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "        (distance_module): Distance()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.utils import standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "train_X = torch.rand(10, 2)\n",
    "Y = 1 - torch.norm(train_X - 0.5, dim=-1, keepdim=True)\n",
    "Y = Y + 0.1 * torch.randn_like(Y)  # add some noise\n",
    "train_Y = standardize(Y)\n",
    "\n",
    "gp = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b083247-34b7-4ee1-8575-2cdd46c090d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6b4989-81ad-4d53-a10b-0b8a2cdaae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b425c7d5-1570-40ae-a60c-7f9ee2f04043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import UpperConfidenceBound\n",
    "\n",
    "UCB = UpperConfidenceBound(gp, beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3f6827-0cc0-4dbf-814c-cebe5fda3ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5512, 0.3481]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "bounds = torch.stack([torch.zeros(2), torch.ones(2)])\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    ")\n",
    "candidate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbe85eb-efc0-4cca-983f-da39fa64da41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7616155-6b86-48ee-8c4a-531af28d0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.distributions.uniform import Uniform\n",
    "massesDistribution = Uniform(low = torch.tensor([2], dtype = float), high = torch.tensor([10], dtype = float))\n",
    "n_parameters = 2    \n",
    "phi_init = np.zeros((n_parameters, 3))\n",
    "return_on_target = np.zeros(3)\n",
    "\n",
    "\"\"\"\n",
    "Populating each column of phi_init with lower (first) and upper (second) bound considered for the distribution\n",
    "sampled from the distribution having [min, max] as parameters\n",
    "\"\"\"\n",
    "\n",
    "for init in range(3): \n",
    "    col_init = np.array([massesDistribution.sample().detach().numpy(), massesDistribution.sample().detach().numpy()]).reshape(-1,)\n",
    "    phi_init[:, init] = col_init\n",
    "\n",
    "    # testing the learned policy in the target environment for n_roll times\n",
    "    roll_return = []\n",
    "    for rollout in range(4): \n",
    "        roll_return.append((col_init @ np.ones_like(col_init)) ** 2)\n",
    "\n",
    "    roll_return = np.array(roll_return)\n",
    "\n",
    "    return_on_target[init] = roll_return.mean()\n",
    "\n",
    "return_on_target = torch.tensor(return_on_target)\n",
    "return_on_target = standardize(return_on_target)\n",
    "\n",
    "# tensorifying Gaussian Process inputs\n",
    "return_on_target, phi_init = return_on_target.reshape(-1,1), torch.tensor(phi_init.T)\n",
    "# fitting a Gaussian Process model\n",
    "gp = SingleTaskGP(return_on_target, phi_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ce15ae-5e2d-4e58-a1c7-fe88fd740955",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedError",
     "evalue": "Must specify a posterior transform when using a multi-output model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m fit_gpytorch_model(mll)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# building an acquisition function\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m UCB \u001b[38;5;241m=\u001b[39m \u001b[43mUpperConfidenceBound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m candidate, _ \u001b[38;5;241m=\u001b[39m optimize_acqf(UCB, bounds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m]]), q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_restarts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(candidate)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polienv/lib/python3.10/site-packages/botorch/acquisition/analytic.py:309\u001b[0m, in \u001b[0;36mUpperConfidenceBound.__init__\u001b[0;34m(self, model, beta, posterior_transform, maximize, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    291\u001b[0m     model: Model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Single-outcome Upper Confidence Bound.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m        maximize: If True, consider the problem a maximization problem.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize \u001b[38;5;241m=\u001b[39m maximize\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(beta):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polienv/lib/python3.10/site-packages/botorch/acquisition/analytic.py:55\u001b[0m, in \u001b[0;36mAnalyticAcquisitionFunction.__init__\u001b[0;34m(self, model, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m posterior_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedError(\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify a posterior transform when using a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-output model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(posterior_transform, PosteriorTransform):\n",
      "\u001b[0;31mUnsupportedError\u001b[0m: Must specify a posterior transform when using a multi-output model."
     ]
    }
   ],
   "source": [
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "# building an acquisition function\n",
    "UCB = UpperConfidenceBound(gp, beta = 0.1)\n",
    "\n",
    "candidate, _ = optimize_acqf(UCB, bounds = torch.tensor([[2, 10], [2, 10]]), q=1, num_restarts=5)\n",
    "\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c39e9-b6ac-4ee2-bad0-c02ef1d324fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
